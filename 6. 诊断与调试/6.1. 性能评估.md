# 性能评估
## 下一步做什么
从第一章到现在，我们已经学习了许多中机器学习的方法。但是在面对如今眼花缭乱的算法时，应当如何选择最合适的算法来对数据集进行学习并改进这个算法？   
思考如下的例子：   
假设已经用波士顿房价数据集得到了线性回归的代价函数：   
$$ J_{\theta}=\frac{1}{2m}[\Sigma_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})^2+λ\Sigma_{j=1}^{m}\theta_j^2]$$   
然而使用这个模型对一个新的房价数据集进行预测的时候，发现误差非常的大，如何改进这个算法的性能？   
有如下几种解决思路：   
1. 获得更多的数据集
2. 选用更少的特征以防止过拟合
3. 获得更多的特征来补充特征集
4. 增加多项式特征
5. 增加或减小正则化参数$λ$    
 
很多人从如上的解决思路中随机地选择几项对人工智能进行优化，然而对于某一种人工智能算法，上述的解决思路不一定每一种都有效。运用本章讲的一些技巧后，能够对如上的解决思路中每一项的有效性进行判别，从而更高效地调试神经网络。    
下面将介绍两种评估机器学习性能的方法，它们被称为**机器学习诊断法**(Machine learning diagnostic)。通过运行这些方法，人们可以了解算法在哪里出现了问题，也能告诉人们做什么样的改进尝试才是有意义的。    
## 评估假设
在3.3.中已经介绍过了过拟合现象，因此单纯地得到预测值和标签的距离很小并不能说明这个假设模型是一个好的模型。   
那么有什么方法能够排除过拟合地评估假设的性能呢？   

答案是划分测试集和训练集， 具体而言：将数据集划分(Split)为测试集和训练集（通常是以3：7的比例随机选择（Shuffle）），将训练集中的样本进行机器学习，测试集进行验证。    
从训练集进行线性回归得到最适合的参数$J(θ)$，再将测试集带入其中：   
$$ J_{test}(\theta)=\frac{1}{2m_{test}}[\Sigma_{i=1}^{m_{test}}(h_θ(x_{test}^{(i)})-y_{test}^{(i)})^2+λ\Sigma_{j=1}^{m_{test}}\theta_j^2]$$  
回归分类中对数据集的划分和验证类型大致同上，只是$J_{test}(\theta)$的形式略有差别。  
对于回归分类还有另一形式的测试度量叫做**错误分类**(Misclassification Error/ 0-1 misclassification error)。   
定义预测值和标签的误差$err(h_θ(x),y)$，有：   
$$err(h_θ(x),y)= 
\begin{cases}
    1  \text{   if     }   h_θ ≥ 0.5, y=0 \text{   or     } h_θ ≤ 0.5, y=1 \\
    0  \text{   if     }   h_θ ≥ 0.5, y=1 \text{   or     } h_θ ≤ 0.5, y=0
\end{cases}
$$
定义测试集的误差：
$$TestError=\frac{1}{m_{test}}∑_{i=1}^{m_{test}}err(h_θ(x^{(i)}_{test}),y^{(i)})$$

## 训练集，测试集和验证集
如果要从如下的多项式中选择一个作为假设模型：  
$$h_θ(x)=θ_0+θ_1x$$
$$h_θ(x)=θ_0+θ_1x+θ_2x^2$$
$$...$$
$$h_θ(x)=θ_0+θ_1x+θ_2x^2+...+θ_nx^n$$
设$d$表示多项式中$x$的最大次数，要测试它们对于样本的泛化能力（即过拟合的程度，泛化能力低意味着模型过拟合，模型能够很好的拟合当前的数据集，但是对新的数据并不敏感），最简单的思路是可以对每一个模型都投入数据集，然后得到最优化的一组向量$Θ^{(d)}$，并从测试集求出每一个$J_{test}(Θ^{(d)})$，然后看哪一个模型的$J_{test}(Θ^{(d)})$最小。  但是由于我们用测试集拟合了$d$，并选择了一个最好的$d$，因此$Θ^{(d)}$很可能是对泛化误差的乐观假设。   
解决办法是对一个数据集分为三个部分：训练集，测试集，和**交叉验证集**（以CV表示）。通常的比例是60%作为训练集，20%作为测试集，20%作为交叉验证集。   
那么定义训练误差，测试误差，验证误差分别为：   
$$ J_{train}(\theta)=\frac{1}{2m}\sum_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})^2$$
$$ J_{test}(\theta)=\frac{1}{2m_{test}}\sum_{i=1}^{m_{test}}(h_θ(x_{test}^{(i)})-y_{test}^{(i)})^2$$
$$ J_{cv}(\theta)=\frac{1}{2m_{cv}}\sum_{i=1}^{m_{cv}}(h_θ(x_{cv}^{(i)})-y_{cv}^{(i)})^2$$
现在使用验证集来选择模型：   
同样地，每一个模型都投入数据集，然后得到最优化的一组向量$Θ^{(d)}$，但是将这些Θ投入验证集并使用交叉验证得到一系列的$J_{cv}(\theta^{(d)})$,找到最合适的$d$，再放入测试集中运行。  