# 数学方法

## 矩阵的运算

### 矩阵的乘法

矩阵的乘法规则：前一矩阵的行乘后一矩阵的纵列若A是一个$m \times n$的矩阵，B是一个$a \times b$的矩阵，那么矩阵乘法$A \times B$的结果将会是一个$n \times a$的矩阵

> 要注意$A × B=0 ⇏A=0 ~or~ B=0$
> $AB \not ={} BA$,但是$(AB)C=A(BC)$

矩阵与向量的乘法可以改写,用如下例子来做表示：
$A=\begin{bmatrix}
1&2&1\\-1&0&2
\end{bmatrix} B=\begin{bmatrix}1\\-1\\1\end{bmatrix}$
有$A\times B=1×\begin{bmatrix}1\\-1\end{bmatrix}+(-1)×\begin{bmatrix}2\\0\end{bmatrix}+1\times \begin{bmatrix}1\\2\end{bmatrix}$
称B是A的一组线性组合

### 转置、对称

$A^T$表示A的转置，即A行列交换后的矩阵。
有$(AB)^{T}=B^{T}A^{T}$
方阵：A为一个正方形矩阵:$m×m$
单位矩阵：\对角线上的元素为1，其余元素为0的方阵，有$AI=IA=A$
若$A^T=A$,称A是一个对称矩阵(Symmetric matrix)，若$A^T=-A$，称A是一个交错矩阵(Skew-symmectric matrix)

### 矩阵的逆

有矩阵$A^{-1}A=I$,称矩阵$A^{-1}$为矩阵A的逆。奇异矩阵不可逆。运算规律：

1. $(AB)^{-1}=B^{-1}A^{-1}$
2. $(A^T)^{-1}=(A^{-1})^{T}$
3. $(A^{-1})^{-1}=A$

### 矩阵方程的解法

对于任何一个线性方程组可以改写成：

$$
Ax=b

$$

A是系数矩阵，x是参数向量，b是方程组右边组成的常数向量
解方程只需要求出$x=Ab$

- 线性无关
  如果A的列向量$a_1,a_2,a_3...a_n$的线性组合为0：

$$
\sum λ_ia_i=0

$$

称这些向量是线性无关的。
A中线性无关列向量的最大数目表示A的秩(Rank)
$Nul(A)$表示线性齐次方程$Ax=0$的解集，它的维度称为零度(Nullity)
如果 $RanK(A)+Nullity(A)=columns~of~A$，可以判断A是可逆的。

### 正交(Orthogonal/Perpenticular)

两个向量$x,y$,如果$x^Ty=0$，称这两个向量是正交的。
如果一个向量集$b_1,b_2,b_3...b_n$中的任意两个元素 $b_i^Tb_j=\begin{dcases}
1, i=j \\ 0, i \not =j
\end{dcases}$
称这个向量集是标准正交集(Orthonormal)
若矩阵Q，$Q^TQ=I$称Q是正交的，它所有的列向量都是正交的

### 行列式计算

det(A)或者|A|记作A的行列式,在Python中可以用numpy库中的函数进行运算。计算性质：

1. $det(AB)=det(A)det(B)$
2. $det(A^{-1})=\frac{1}{det(A)}$
   所以det(A)=0时，A不可逆
3. $det(A^T)=det(A)$
4. $det(kA)=k^ndet(A)$,A_{n \times n}
5. $det(A)=Πλ_i$

### 特征值/特征向量

若有$Ax=λx$,λ称为A的特征值(Eigenvalue)，x称为A的特征向量(Eigenvector)

> 特征值可能是一个复数，矩阵的特征向量/特征值可能有几个是相同的
> $kλ$和$kx$仍然是A的特征值和特征向量，所以默认解出的特征向量的模长(Norm)为1。

- 求解特征值/特征向量
  通过$det(A-λI)=0$，求解$λ$,再代回$Ax-λx=0$求解x
- 谱分解(Spectral Theorem)
  A所有的特征值和特征向量可以写成一个矩阵方程：

  $$
  A \begin{bmatrix}
    x_1&x_2&...&x_n
  \end{bmatrix}=\begin{bmatrix}
    x_1&x_2&...&x_n
  \end{bmatrix}\begin{bmatrix}
    λ_1 &&&&\\ &λ_2\\&&λ_3\\&&&...
  \end{bmatrix}$$

  $\begin{bmatrix}
  λ_1 &&&&\\ &λ_2\\&&λ_3\\&&&...
  \end{bmatrix}$ 称为A的对角矩阵(Diagonal matrix)$Λ$
  记作$AE=EΛ$
  如果E是可逆矩阵，$A=EΛE^{-1}$
  如果A是对称矩阵，有$E^{-1}=E^T$,$A=EΛE^T$
  在机器学习中，A常常是对称的，而且所有的特征值都是实数

### 迹(Trace)

矩阵A的\对角线元素的总和称为A的迹：

$$
tr(A)=\sum a_{ii}

$$

它在数值上也等于所有特征值的和：

$$
tr(A)=\sum λ_{i}

$$

计算性质：

1. $tr(AB)=tr(BA)$
2. $tr(A+B)=tr(A)+tr(B)$

### 伪逆矩阵(Pseudo-inverse)

当A不可逆时，要解决$Ax=b$,转写为$x=A^{-1}b$的形式求解x看似不可能，因此构造矩阵$A^{+}$,使得$x=A^{+}b,Ax-b$的模长最小，$A^+$称为A的伪逆矩阵。

$$
A^+=(A^TA)^{-1}A^T

$$

$$
A^+A=(A^TA)^{-1}A^TA=I

$$

$$
AA^+=A (A^TA)^{-1}A^T\not=I

$$

在Python中`pinv(A)`可以实现求解伪逆矩阵

### 矩阵的导数

矩阵的导数满足如下性质：

1. $\frac{d}{dx}Ax=A^T$
2. $\frac{dx}{dx}=I$
3. $\frac{y^Tx}{dx}=\frac{dx^Ty}{dx}=y$
4. $\frac{d(x^TAx)}{dx}=\begin{dcases}
   (A+A^T)x,A~is~square\\2Ax,A~is~symmetrix
   \end{dcases}$
5. $\frac{d(u^T(x)~v(x))}{dx}=[\frac{du^T}{dx}]v+[\frac{dv^T}{dx}]u$
6. $\frac{d~tr(A)}{dA}=I$
7. $\frac{det(A)}{dA}=det(A)(A^{-1})^T$

- 伪逆矩阵证明当A为奇异矩阵时，求解$Ax=b$:定义误差(error)$e=Ax-b$，要使得$|e|$尽可能小：设$y=|e|^2$，$y=e^Te$$~~~=(Ax-b)^T(Ax-b)$$~~~=(Ax)^T(Ax)-(Ax)^Tb-b^T(Ax)+b^Tb$$~~~=x^TA^TAx-2b^T(Ax)+b^Tb$对y求导：$\frac{dy}{dx}=2A^TAx-2A^Tb+0$

  > 第一项，$A^TA$是一个对称矩阵，可以应用#4.
  > 第二项，应用#3
  > 第三项，$b^Tb$是一个常数
  >

  令$\frac{dy}{dx}=2A^TAx-2A^Tb=0$：

  $$
  A^TAx=A^Tb

  $$

$$
(A^TA)^{-1}A^Tb=A^+b

$$

在Python中，`linalg.solve(A,B)`能够求解$x=A^+b$     

## 概率论的基础概念
- 随机变量  
  随机实验是一种能够产生随机结果的可重复性实验，样本空间$S$表示随机实验中所有可能出现的结果构成的集合，事件(Event)是样本空间S的子集。  
  随机变量(Random variables)是将S对应到实数集的一种函数，概率分布函数(MPF)表示X在样本空间中所发生的概率与X之间的关系。概率密度函数(PDF)表示样本空间中概率分布的稠密程度。    
- 常见的随机分布  
  *具体翻阅概率论笔记，此处不再赘述。
  两点分布(Bernouli)  
  几何分布(Geometric)  
  二项分布(Binomial)  
  泊松分布(Poisson)
  均匀分布(Uniform)   
  指数分布(Exponential)  
  双指数分布(Laplace/Double Exponential): $F(x)=\frac{λ}{2}e^{-λ|x|},λ>0$  
  正态分布(Gaussian/Normal)  

- 其他分布函数概念
  联合概率密度/联合分布函数(Joint PDF)    
  边缘分布函数(Marginal PDF)    
  条件概率函数(Conditional PDF)   

## 贝叶斯公式  
  全概率公式的逆公式，表示已知B事件发生的概率下，在A中某一个划分下发生的概率：
  $$P(A_i|B)=\frac{P(A_i)P(B|A_i)}{P(B)}=\frac{P(A_i)P(B|A_i)}{ΣP(A_i)P(B|A_i)}$$   
  
