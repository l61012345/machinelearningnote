<style>
img{
    width: 60%;
    padding-left: 20%;
}
</style>
# 梯度下降算法
在开始之前，为了方便解释，首先规定几个符号所代表的意义：  
$m$ 训练集中训练样本的数量  
$X$  输入变量  
$Y$  输出变量  
$(x,y)$ 训练样本  
$(x^i,y^i)$第i个训练样本（i表示一个索引）  
## 监督学习算法的流程
提供训练集>学习算法得到h（假设函数：用于描绘x与y的关系）>预测y 的值  
## 代价/损失函数（Cost function）  
**假设函数(hypothesis function)**——$h$是用来表示某一个数据集可能存在的线性/非线性关系的函数。  
$$h_θ(x)=θ_1x+θ_0$$
这其中的$θ$是假设函数当中的参数。
也可以简化为：
$$h_θ(x)=θ_1x$$  
**代价函数**，在统计学上称为均方根误差函数。当假设函数中的系数$θ$取不同的值时，$\frac{1}{2m}$倍假设函数预测值$h_θ(x^{(i)})$和真实值$y^{(i)}$的差的平方的和之间的函数关系表示为代价函数$J$。
$$J(θ_0,θ_1)=\frac{1}{2m}∑_{i=1}^m(h_θ(x^{(i)})-y^{(i)})^2$$
函数在几何上表示为数据集空间内的各点到假设函数的距离的平方的平均值的一半。  
> 在这里取1/2的原因是便于消除求导之后产生的2倍,同时也可以进一步缩小$θ$  

> 该函数的自变量是$θ_1$和$θ_0$，因此该函数是三维的函数（如图所示）。  
 ![](https://raw.githubusercontent.com/l61012345/Pic/master/img/20210131130651.png)  


