# 神经网络的背景知识
## 激活函数算法的局限性
假设一个数据集拥有非常多的原始特征和数据量，执行激活函数算法，那么次方项、交叉项会非常的多，计算量非常的大，最终的拟合结果也不好。  
计算机视觉中的例子：  
计算机读取到的是图片所对应的像素强度的矩阵。 
>对于灰度图像来说，像素强度就是每一个像素的灰度值。  
>对于RGB彩色图像来说，图片上的一个像素以三个值（R,G,B）/三维向量 来进行表示  

如果现在设计一个分类器，使得计算机能够区分一个图片的主体是否为汽车。
![](https://raw.githubusercontent.com/l61012345/Pic/master/img/472E9216086782CF8029F2818CA1027A.png)
以pixel1 和 pixel2的位置为例，我们可以把所有数据集中pixel1和pixel2的像素强度投射到坐标轴上，如图使用一个非线性假设来对图像进行分类。  
如果对于一个50*50像素的图片数据集，那么训练集中将包含至少2500个原始特征（7500 RGB），这时候用激活函数算法计算量会非常的大。  

## 神经元模型 
假设： 大脑对于不同功能（听觉，视觉，触觉的处理）的实现是依赖于同样的学习方法  
依据： 神经重接实验  
神经网络模拟了大脑中的神经元或者是神经网络。先来看大脑中的神经元构成，我们会发现神经元有很多的输入通道（树突），同时通过轴突给其他的神经元传递信号。  
将神经元简单抽象：一个计算单元，它从输入端接收一定数目的信息，并作一些处理，并将结果传递给其他的神经元。  
在计算机中，我们构建一个逻辑单元，它从输入端接收数据集X，并作处理来生成一个激活函数$h_θ (x)=\frac{1}{1+e^{-θ^T X}}$
![](https://raw.githubusercontent.com/l61012345/Pic/master/img/20201229183932.png)
在这个模型之上，输入端会额外增加一个$x_0=1$，称为偏置单元。  
在神经网络中，$Θ$称为模型的权重，$g(z)=\frac{1}{1+e^{-z}}$称为激活函数。  

神经网络是一组神经元连接在一起的集合，如图所示  
![](https://raw.githubusercontent.com/l61012345/Pic/master/img/20201229184740.png)
第一层称为输入层，我们在这一层输入全部的特征，最后一层称为输出层，这一层的神经元输出假设的最终结果，中间的层称为隐藏层，隐藏层可能不止有一层。  
统一地，$a_i^(j)$将表示第j层的第i个激活项（激活指计算并输出结果），同时，第j层到第j+1层之间的映射由参数矩阵$Θ^(j)$确定，那么上图就可以用公式表示为：
![](https://raw.githubusercontent.com/l61012345/Pic/master/img/20201229185615.png)
如果一个网络在第j层有$s_j$个单元，且在第j+1层有$s_j+1$个单元，那么矩阵$Θ^(j)$的维度为$s_{j+1} \times (s_j+1)$