# 数学方法
## 矩阵的运算
### 矩阵的乘法
矩阵的乘法规则：  
前一矩阵的行乘后一矩阵的纵列  
若A是一个$m \times n$的矩阵，B是一个$a \times b$的矩阵，那么矩阵乘法$A \times B$的结果将会是一个$n \times a$的矩阵 
> 要注意$A × B=0 ⇏A=0 ~or~ B=0$  
> $AB \not ={} BA$,但是$(AB)C=A(BC)$   

矩阵与向量的乘法可以改写,用如下例子来做表示：  
$A=\begin{bmatrix}
    1&2&1\\-1&0&2
\end{bmatrix} B=\begin{bmatrix}1\\-1\\1\end{bmatrix}$  
有$A\times B=1×\begin{bmatrix}1\\-1\end{bmatrix}+(-1)×\begin{bmatrix}2\\0\end{bmatrix}+1\times \begin{bmatrix}1\\2\end{bmatrix}$   
称B是A的一组线性组合  
### 转置、对称
$A^T$表示A的转置，即A行列交换后的矩阵。 
有$(AB)^{T}=B^{T}A^{T}$ 
方阵：A为一个正方形矩阵:$m×m$  
单位矩阵：\对角线上的元素为1，其余元素为0的方阵，有$AI=IA=A$  
若$A^T=A$,称A是一个对称矩阵(Symmetric matrix)，若$A^T=-A$，称A是一个交错矩阵(Skew-symmectric matrix)   
### 矩阵的逆
有矩阵$A^{-1}A=I$,称矩阵$A^{-1}$为矩阵A的逆。奇异矩阵不可逆。   
运算规律：  
1. $(AB)^{-1}=B^{-1}A^{-1}$  
2. $(A^T)^{-1}=(A^{-1})^{T}$
3. $(A^{-1})^{-1}=A$
### 矩阵方程的解法
对于任何一个线性方程组可以改写成：
$$Ax=b$$
A是系数矩阵，x是参数向量，b是方程组右边组成的常数向量
解方程只需要求出$x=Ab$
- 线性无关  
如果A的列向量$a_1,a_2,a_3...a_n$的线性组合为0：
$$\sum λ_ia_i=0$$
称这些向量是线性无关的。  
A中线性无关列向量的最大数目表示A的秩(Rank)  
$Nul(A)$表示线性齐次方程$Ax=0$的解集，它的维度称为零度(Nullity)
如果 $RanK(A)+Nullity(A)=columns~of~A$，可以判断A是可逆的。
### 正交(Orthogonal/Perpenticular)
两个向量$x,y$,如果$x^Ty=0$，称这两个向量是正交的。  
如果一个向量集$b_1,b_2,b_3...b_n$中的任意两个元素 $b_i^Tb_j=\begin{dcases}
    1, i=j \\ 0, i \not =j
\end{dcases}$
称这个向量集是标准正交集(Orthonormal)   
若矩阵Q，$Q^TQ=I$称Q是正交的，它所有的列向量都是正交的 
### 行列式计算  
det(A)或者|A|记作A的行列式,在Python中可以用numpy库中的函数进行运算。  
计算性质： 
1. $det(AB)=det(A)det(B)$
2. $det(A^{-1})=\frac{1}{det(A)}$  
   所以det(A)=0时，A不可逆
3. $det(A^T)=det(A)$
4. $det(kA)=k^ndet(A)$,A_{n \times n}
5. $det(A)=Πλ_i$
### 特征值/特征向量  
若有$Ax=λx$,λ称为A的特征值(Eigenvalue)，x称为A的特征向量(Eigenvector)  
> 特征值可能是一个复数，矩阵的特征向量/特征值可能有几个是相同的   
$kλ$和$kx$仍然是A的特征值和特征向量，所以默认解出的特征向量的模长(Norm)为1。    
- 求解特征值/特征向量  
  通过$det(A-λI)=0$，求解$λ$,再代回$Ax-λx=0$求解x  
- 谱分解(Spectral Theorem)    
  A所有的特征值和特征向量可以写成一个矩阵方程：
  $$A \begin{bmatrix}
    x_1&x_2&...&x_n
  \end{bmatrix}=\begin{bmatrix}
    x_1&x_2&...&x_n
  \end{bmatrix}\begin{bmatrix}
    λ_1 &&&&\\ &λ_2\\&&λ_3\\&&&...
  \end{bmatrix}$$  
  $\begin{bmatrix}
    λ_1 &&&&\\ &λ_2\\&&λ_3\\&&&...
  \end{bmatrix}$ 称为A的对角矩阵(Diagonal matrix)$Λ$  
  记作$AE=EΛ$   
  如果E是可逆矩阵，$A=EΛE^{-1}$  
  如果A是对称矩阵，有$E^{-1}=E^T$,$A=EΛE^T$  
  在机器学习中，A常常是对称的，而且所有的特征值都是实数  

### 迹(Trace)  
矩阵A的\对角线元素的总和称为A的迹：  
$$tr(A)=\sum a_{ii}$$
它在数值上也等于所有特征值的和：  
$$tr(A)=\sum λ_{i}$$
计算性质：
1. $tr(AB)=tr(BA)$
2. $tr(A+B)=tr(A)+tr(B)$

### 伪逆矩阵(Pseudo-inverse)
当A不可逆时，要解决$Ax=b$,转写为$x=A^{-1}b$的形式求解x看似不可能，因此构造矩阵$A^{+}$,使得$x=A^{+}b,Ax-b$的模长最小，$A^+$称为A的伪逆矩阵。  
$$A^+=(A^TA)^{-1}A^T$$
$$A^+A=(A^TA)^{-1}A^TA=I$$ 
$$AA^+=A (A^TA)^{-1}A^T\not=I$$   
在Python中`pinv(A)`可以实现求解伪逆矩阵   
### 矩阵的导数
矩阵的导数满足如下性质：
1. $\frac{d}{dx}Ax=A^T$  
2. $\frac{dx}{dx}=I$  
3. $\frac{y^Tx}{dx}=\frac{dx^Ty}{dx}=y$  
4. $\frac{d(x^TAx)}{dx}=\begin{dcases}
    (A+A^T)x,A~is~square\\2Ax,A~is~symmetrix
   \end{dcases}$  
5. $\frac{d(u^T(x)~v(x))}{dx}=[\frac{du^T}{dx}]v+[\frac{dv^T}{dx}]u$  
6. $\frac{d~tr(A)}{dA}=I$  
7. $\frac{det(A)}{dA}=det(A)(A^{-1})^T$  
- 伪逆矩阵证明    
  当A为奇异矩阵时，求解$Ax=b$:  
  定义误差(error)$e=Ax-b$，要使得$|e|$尽可能小：  
  设$y=|e|^2$，  
  $y=e^Te$  
  $~~~=(Ax-b)^T(Ax-b)$  
  $~~~=(Ax)^T(Ax)-(Ax)^Tb-b^T(Ax)+b^Tb$     
  $~~~=x^TA^TAx-2b^T(Ax)+b^Tb$  
  对y求导：  
  $\frac{dy}{dx}=2A^TAx-2A^Tb+0$
  >第一项，$A^TA$是一个对称矩阵，可以应用#4.  
  >第二项，应用#3  
  >第三项，$b^Tb$是一个常数  

  令$\frac{dy}{dx}=2A^TAx-2A^Tb=0$：  
  $$A^TAx=A^Tb$$
  $$x=(A^TA)^{-1}A^Tb=A^+b$$
  在Python中，`linalg.solve(A,B)`能够求解$x=A^+b$